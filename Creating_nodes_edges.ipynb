{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ampazio/hallow-universe/blob/main/Creating_nodes_edges.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First step: lexical analysis in MAXQDA**.\n",
        "\n",
        "Open MAXDiction > Dictionary. Add categories. One category = one code (no spaces between multi-word entity names). To each caterogy we add word variations that the dictionary should recognize, for example: if our category is JonathanRoumie, we include \"Jonathan Roumie\" as position.\n",
        "\n",
        "We then conduct a content analysis based on the dictionary and code our documents automatically with the results."
      ],
      "metadata": {
        "id": "nitl4oGPM5xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second step: Co-occurence analysis in MAXQDA**. We have to make sure that each code is made up of just one word (no gaps).\n",
        "\n",
        "Activate all documents and all codes.\n",
        "\n",
        "Go to the \"Analysis\" option and choose \"Complex Coding Query\". In the window that opens, under \"Function\" choose \"Intersection (set)\",\n",
        "make sure all codes are activated and set the minimum code number to 2.\n",
        "\n",
        "Then in the \"Retrieved segments\" section in the MAXQDA bottom panel choose \"Export as Excel file\". Choose \"other codes ascribed to segment\". Save the file.\n",
        "\n",
        "Open the file in Excel and save it in .csv UTF-8 format.\n",
        "\n",
        "Upload this .csv file to COLAB and insert it into the file's path into the script below."
      ],
      "metadata": {
        "id": "1k1HLfsDLbB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import the CSV file\n",
        "file_path = '/content/MAXQDA 2_KODY.csv'  # Change to your file name\n",
        "data = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
        "\n",
        "# Change the name of column B\n",
        "data.rename(columns={'Inne kody przypisane do segmentu': 'kod'}, inplace=True)\n",
        "\n",
        "# Clean data in the 'kod' column\n",
        "if 'kod' in data.columns:\n",
        "    data['kod'] = data['kod'].astype(str).str.replace(r'\\(Waga: 0\\)', '', regex=True)  # Remove phrases \"(Waga: 0)\"\n",
        "    data['kod'] = data['kod'].str.replace('\"', '')  # Usuń zbędne cudzysłowy\n",
        "    data['kod'] = data['kod'].str.split().apply(lambda x: ';'.join(filter(None, x)))  # Combine remaining words with semi-colons\n",
        "\n",
        "# Save the processed file\n",
        "output_path = 'przetworzony_plik.csv'  # Path to file\n",
        "data.to_csv(output_path, sep=';', index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"Plik został przetworzony i zapisany jako {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-AK8h7n-nuK",
        "outputId": "c56840ff-2971-4349-b8b6-31be82a7d534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plik został przetworzony i zapisany jako przetworzony_plik.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our file has been cleaned, we can insert it into the script below."
      ],
      "metadata": {
        "id": "SnqTl75iMRcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data, using semi-colons as delimiters\n",
        "data = pd.read_csv('/content/przetworzony_plik.csv', delimiter=';')\n",
        "\n",
        "# Verity column names\n",
        "print(data.columns)\n",
        "\n",
        "# Remove superfluous spaces in column names\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Check whether 'kod' includes empty values\n",
        "data['kod'] = data['kod'].fillna('')  # Replces empty values with empty strings\n",
        "\n",
        "# Separate the \"kod\" kolumn into separate codes (now ID lists)\n",
        "data['kod'] = data['kod'].str.split(';')\n",
        "\n",
        "# Create list of all unique codes (actors from the 'kod' column)\n",
        "all_codes = set()\n",
        "for codes in data['kod']:\n",
        "    all_codes.update(codes)\n",
        "\n",
        "# Ascribe unique ID numbers to each code\n",
        "code_to_id = {code: idx + 1 for idx, code in enumerate(all_codes)}\n",
        "\n",
        "# Replaces codes with their IDs in the 'kod' column\n",
        "data['kod'] = data['kod'].apply(lambda x: [code_to_id[code] for code in x])\n",
        "\n",
        "# Creating a list of edges (relationships between codes within the same segment)\n",
        "edges = []\n",
        "\n",
        "# For each data row\n",
        "for idx, row in data.iterrows():\n",
        "    codes = row['kod']  # List of codes ascribed to segment\n",
        "\n",
        "    # Create unique code pairs within each segment\n",
        "    for i in range(len(codes)):\n",
        "        for j in range(i + 1, len(codes)):\n",
        "            edges.append([codes[i], codes[j], 'Undirected', 1])\n",
        "\n",
        "# Create DataFrame for edges\n",
        "edges_df = pd.DataFrame(edges, columns=['Source', 'Target', 'Type', 'Weight'])\n",
        "\n",
        "# Create DataFrame for nodes (code_id and code_name)\n",
        "nodes = pd.DataFrame({\n",
        "    'Id': [code_to_id[code] for code in all_codes],\n",
        "    'Label': [code for code in all_codes]\n",
        "})\n",
        "\n",
        "# Save CSV files\n",
        "nodes.to_csv('nodes.csv', index=False, sep=';')  # Węzły (kody)\n",
        "edges_df.to_csv('edges.csv', index=False, sep=';')  # Krawędzie (relacje między kodami)\n",
        "\n",
        "print(\"Pliki nodes.csv i edges.csv zostały wygenerowane.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEV-BaeZHhNX",
        "outputId": "411582af-1e4d-4dde-961a-9afabf8be0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Segment', 'kod'], dtype='object')\n",
            "Pliki nodes.csv i edges.csv zostały wygenerowane.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import both files into Gephi.\n",
        "Visualize the relationships between the nodes using available algorithms, such as ForceAtlas2. The size of the nodes can be regulated so that it reflects the degree centrality of the nodes. Communities can be identified via the use of modularity statistics."
      ],
      "metadata": {
        "id": "m120fsloG0mx"
      }
    }
  ]
}